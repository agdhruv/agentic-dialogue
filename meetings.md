## Jack
- Better for workshop at ACL etc.
- cot vs conversation - set up a baseline -- dig into this more

Next steps:
- Decide venue + workshop + standards
- 4 page vs 8 page papers
- More experiments -- only after deciding on venue (ACL, EMNLP, NAACL, etc.)
- COLM is more ML focused - COLING might be better

## Kaitlyn
- Test against debias + CoT (SOTA), want to be close to SOTA (not necessarily SOTA)
- Contribution: agent conversation to reveal what CoT doesn’t (one agent vs reasoning in an interactive setting)
- Can it also work on MMLU or other questions (even if anchor the paper to debiasing)
- Uncertainty markers on their own without asking them to do it
- Very robust with methods — method, dataset, prompting technique, duplicates, justification. Try other paraphrases, do you get similar results (hyper parameter search)
- What happens when there are more agents (ablations)
- Corpus analysis — why does it work? Cristian might be able to help with this
- Long paper (8 not 4)
- ARR April 15? COLM? FAccT? ICLR?
- Take more models — show worst 5 and top 5
- Triple check that the models are different, assign personas, etc.
- AI Safety positioning: discussion?
- Framing could be: other that CoT, what can we do to support reasoning.

## Brihi:
- There are already a lot of guardrails for prevent some of this bias, then why do we still care about this problem.
- Evaluate in other social settings where big models fail (e.g., bias in personas, SocialQA, to CoT or not to CoT paper)
- LLM-as-a-judge/jury literature.
- Instead of evaluation, can pitch it as a tool to improve reasoning capabilities.